{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a615fcc",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048e82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Custom imports\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from classification.ml_logic.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df5e9f",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066937c9",
   "metadata": {},
   "source": [
    "### 1.1 Dataframe loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c453cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Detection data loaded successfully. 3383 records found.\n",
      "Mini-DDSM data loaded successfully. 7808 records found.\n",
      "Final dataset size after removing missing labels: 7808 records.\n",
      "Total images: 7808\n",
      "Total unique patients: 1692\n",
      "Original class distribution:\n",
      "Status\n",
      "Cancer    2716\n",
      "Benign    2684\n",
      "Normal    2408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Binary class distribution:\n",
      "Non-Cancer (Benign + Normal): 5092\n",
      "Cancer: 2716\n"
     ]
    }
   ],
   "source": [
    "bcd_root_dir = Path('../raw_data/breast-cancer-detection')\n",
    "mini_ddsm_root_dir = Path('../raw_data/MINI-DDSM-Complete-JPEG-8')\n",
    "\n",
    "# Import breast-cancer-detection dataset\n",
    "data = []\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = bcd_root_dir / split\n",
    "    for label in ['0', '1']:\n",
    "        label_dir = split_dir / label\n",
    "        for img_path in label_dir.glob('*.jpg'):\n",
    "            data.append({\n",
    "                'image_name': img_path.name,\n",
    "                'image_path': str(img_path),\n",
    "                'label': int(label),\n",
    "                'split': split\n",
    "            })\n",
    "\n",
    "bcd_df = pd.DataFrame(data)\n",
    "print(f'Breast Cancer Detection data loaded successfully. {len(bcd_df)} records found.')\n",
    "\n",
    "bcd_train_df = bcd_df[bcd_df['split'] == 'train']\n",
    "bcd_val_df = bcd_df[bcd_df['split'] == 'valid']\n",
    "bdc_test_df = bcd_df[bcd_df['split'] == 'test']\n",
    "\n",
    "# Import MINI-DDSM dataset\n",
    "\n",
    "# Load Excel file\n",
    "mini_ddsm_df = pd.read_excel(os.path.join(mini_ddsm_root_dir, 'DataWMask.xlsx'))\n",
    "print(f'Mini-DDSM data loaded successfully. {len(mini_ddsm_df)} records found.')\n",
    "# print(mini_ddsm_df.head())\n",
    "\n",
    "# Replace backslashes with forward slashes in fullPath\n",
    "mini_ddsm_df['fullPath'] = mini_ddsm_df['fullPath'].str.replace('\\\\', '/', regex=False)\n",
    "# Ensure fullPath is a string\n",
    "mini_ddsm_df['fullPath'] = mini_ddsm_df['fullPath'].astype(str)\n",
    "\n",
    "# Extract patiend ID from fileName (format: C_{patient_id}_1_LATERALITY_VIEW.jpg)\n",
    "mini_ddsm_df['fileName'] = mini_ddsm_df['fileName'].astype(str).str.strip()\n",
    "mini_ddsm_df['patient_id'] = mini_ddsm_df['fileName'].str.extract(r'\\w_(\\d+)_1')\n",
    "\n",
    "# Binary mapping: Cancer = 1, Benign and Normal = 0\n",
    "def create_binary_labels(status):\n",
    "    if status == 'Cancer':\n",
    "        return 1\n",
    "    else: # Benign or Normal\n",
    "        return 0\n",
    "\n",
    "mini_ddsm_df['binary_label'] = mini_ddsm_df['Status'].apply(create_binary_labels)\n",
    "\n",
    "# Remove any rows with missing labels\n",
    "mini_ddsm_df = mini_ddsm_df.dropna(subset=['binary_label', 'patient_id'])\n",
    "print(f'Final dataset size after removing missing labels: {len(mini_ddsm_df)} records.')\n",
    "\n",
    "print(f\"Total images: {len(mini_ddsm_df)}\")\n",
    "print(f\"Total unique patients: {mini_ddsm_df['patient_id'].nunique()}\")\n",
    "print(f\"Original class distribution:\\n{mini_ddsm_df['Status'].value_counts()}\")\n",
    "print(f\"\\nBinary class distribution:\")\n",
    "print(f\"Non-Cancer (Benign + Normal): {len(mini_ddsm_df[mini_ddsm_df['binary_label'] == 0])}\")\n",
    "print(f\"Cancer: {len(mini_ddsm_df[mini_ddsm_df['binary_label'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1730003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient distribution:\n",
      "Train patients: 1184\n",
      "Validation patients: 253\n",
      "Test patients: 255\n",
      "\n",
      "Image distribution:\n",
      "Train images: 5480 (Cancer: 1880, Non-Cancer: 3600)\n",
      "Val images: 1144 (Cancer: 412, Non-Cancer: 732)\n",
      "Test images: 1184 (Cancer: 424, Non-Cancer: 760)\n",
      "✓ No patient leakage detected!\n"
     ]
    }
   ],
   "source": [
    "def patient_based_split(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data by patient ID to avoid data leakage.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image data with 'patient_id' and 'Status'.\n",
    "        train_ratio (float): Proportion of data to use for training.\n",
    "        val_ratio (float): Proportion of data to use for validation.\n",
    "        test_ratio (float): Proportion of data to use for testing.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "    Returns:\n",
    "        tuple: DataFrames for train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    # Get unique patients with their status\n",
    "    patient_info = df.groupby('patient_id')['Status'].first().reset_index()\n",
    "    patient_info['binary_label'] = patient_info['Status'].apply(create_binary_labels)\n",
    "\n",
    "    unique_patients = patient_info['patient_id'].unique()\n",
    "\n",
    "    # Shuffle patients\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_patients)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_patients = len(unique_patients)\n",
    "    train_size = int(train_ratio * total_patients)\n",
    "    val_size = int(val_ratio * total_patients)\n",
    "\n",
    "    # Split patient IDs\n",
    "    train_patients = unique_patients[:train_size]\n",
    "    val_patients = unique_patients[train_size:train_size+val_size]\n",
    "    test_patients = unique_patients[train_size+val_size:]\n",
    "\n",
    "    print(f\"\\nPatient distribution:\")\n",
    "    print(f\"Train patients: {len(train_patients)}\")\n",
    "    print(f\"Validation patients: {len(val_patients)}\")\n",
    "    print(f\"Test patients: {len(test_patients)}\")\n",
    "\n",
    "    # Assign split labels to all images based on patient ID\n",
    "    def assign_split(patient_id):\n",
    "        if patient_id in train_patients:\n",
    "            return 'train'\n",
    "        elif patient_id in val_patients:\n",
    "            return 'val'\n",
    "        else:\n",
    "            return 'test'\n",
    "\n",
    "    df['split'] = df['patient_id'].apply(assign_split)\n",
    "\n",
    "    # Create separate dataframes\n",
    "    train_df = df[df['split'] == 'train'].copy()\n",
    "    val_df = df[df['split'] == 'val'].copy()\n",
    "    test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nImage distribution:\")\n",
    "    print(f\"Train images: {len(train_df)} (Cancer: {sum(train_df['binary_label'])}, Non-Cancer: {len(train_df) - sum(train_df['binary_label'])})\")\n",
    "    print(f\"Val images: {len(val_df)} (Cancer: {sum(val_df['binary_label'])}, Non-Cancer: {len(val_df) - sum(val_df['binary_label'])})\")\n",
    "    print(f\"Test images: {len(test_df)} (Cancer: {sum(test_df['binary_label'])}, Non-Cancer: {len(test_df) - sum(test_df['binary_label'])})\")\n",
    "\n",
    "    # Verify no patient leakage\n",
    "    train_patients_set = set(train_df['patient_id'].unique())\n",
    "    val_patients_set = set(val_df['patient_id'].unique())\n",
    "    test_patients_set = set(test_df['patient_id'].unique())\n",
    "\n",
    "    assert len(train_patients_set.intersection(val_patients_set)) == 0, \"Patient leakage between train and val!\"\n",
    "    assert len(train_patients_set.intersection(test_patients_set)) == 0, \"Patient leakage between train and test!\"\n",
    "    assert len(val_patients_set.intersection(test_patients_set)) == 0, \"Patient leakage between val and test!\"\n",
    "\n",
    "    print(\"✓ No patient leakage detected!\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Execute the split\n",
    "mini_ddsm_train_df, mini_ddsm_val_df, mini_ddsm_test_df = patient_based_split(mini_ddsm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79b3f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image paths for MINI-DDSM dataset\n",
    "mini_ddsm_train_df['image_path'] = mini_ddsm_train_df['fullPath'].apply(lambda x: str(mini_ddsm_root_dir / x))\n",
    "mini_ddsm_val_df['image_path'] = mini_ddsm_val_df['fullPath'].apply(lambda x: str(mini_ddsm_root_dir / x))\n",
    "mini_ddsm_test_df['image_path'] = mini_ddsm_test_df['fullPath'].apply(lambda x: str(mini_ddsm_root_dir / x))\n",
    "\n",
    "# Remove unnecessary columns\n",
    "mini_ddsm_train_df = mini_ddsm_train_df[['fileName', 'image_path', 'binary_label', 'split']]\n",
    "mini_ddsm_val_df = mini_ddsm_val_df[['fileName', 'image_path', 'binary_label', 'split']]\n",
    "mini_ddsm_test_df = mini_ddsm_test_df[['fileName', 'image_path', 'binary_label', 'split']]\n",
    "\n",
    "## Rename columns for consistency\n",
    "# fileName to image_name\n",
    "mini_ddsm_train_df.rename(columns={'fileName': 'image_name'}, inplace=True)\n",
    "mini_ddsm_val_df.rename(columns={'fileName': 'image_name'}, inplace=True)\n",
    "mini_ddsm_test_df.rename(columns={'fileName': 'image_name'}, inplace=True)\n",
    "# binary_label to label\n",
    "mini_ddsm_train_df.rename(columns={'binary_label': 'label'}, inplace=True)\n",
    "mini_ddsm_val_df.rename(columns={'binary_label': 'label'}, inplace=True)\n",
    "mini_ddsm_test_df.rename(columns={'binary_label': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e499754",
   "metadata": {},
   "source": [
    "#### 1.1.1 Downsampling individual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0419a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution:\n",
      "label\n",
      "0    1569\n",
      "1     803\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced distribution:\n",
      "label\n",
      "0    803\n",
      "1    803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# breast-cancer-detection dataset downsampling\n",
    "# Separate majority and minority classes\n",
    "bcd_train_majority_class = bcd_train_df[bcd_train_df['label'] == 0]\n",
    "bcd_train_minority_class = bcd_train_df[bcd_train_df['label'] == 1]\n",
    "\n",
    "# Downsample majority class to match minority class size\n",
    "bcd_train_majority_downsampled = bcd_train_majority_class.sample(n=len(bcd_train_minority_class), random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "bcd_train_balanced = pd.concat([bcd_train_majority_downsampled, bcd_train_minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "bcd_train_balanced = bcd_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Original distribution:\")\n",
    "print(bcd_train_df['label'].value_counts())\n",
    "print(\"\\nBalanced distribution:\")\n",
    "print(bcd_train_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7755a3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution:\n",
      "label\n",
      "0    3600\n",
      "1    1880\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced distribution:\n",
      "label\n",
      "0    1880\n",
      "1    1880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# mini-ddsm dataset downsampling\n",
    "# Separate majority and minority classes\n",
    "mini_ddsm_train_majority_class = mini_ddsm_train_df[mini_ddsm_train_df['label'] == 0]\n",
    "mini_ddsm_train_minority_class = mini_ddsm_train_df[mini_ddsm_train_df['label'] == 1]\n",
    "\n",
    "# Downsample majority class to match minority class size\n",
    "mini_ddsm_train_majority_downsampled = mini_ddsm_train_majority_class.sample(n=len(mini_ddsm_train_minority_class), random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "mini_ddsm_train_balanced = pd.concat([mini_ddsm_train_majority_downsampled, mini_ddsm_train_minority_class])\n",
    "\n",
    "# Shuffle the dataset\n",
    "mini_ddsm_train_balanced = mini_ddsm_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Original distribution:\")\n",
    "print(mini_ddsm_train_df['label'].value_counts())\n",
    "print(\"\\nBalanced distribution:\")\n",
    "print(mini_ddsm_train_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e95dcb",
   "metadata": {},
   "source": [
    "#### 1.1.1 Changing and combining dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fc7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset sizes:\n",
      "Train set: 5366\n",
      "Validation set: 1819\n",
      "Test set: 1520\n",
      "\n",
      "Combined class distribution in train set:\n",
      "label\n",
      "0    2683\n",
      "1    2683\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Combined class distribution in validation set:\n",
      "label\n",
      "0    1180\n",
      "1     639\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Combined class distribution in test set:\n",
      "label\n",
      "0    968\n",
      "1    552\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Combine datasets\n",
    "combined_train_df = pd.concat([bcd_train_balanced, mini_ddsm_train_balanced], ignore_index=True)\n",
    "combined_val_df = pd.concat([bcd_val_df, mini_ddsm_val_df], ignore_index=True)\n",
    "combined_test_df = pd.concat([bdc_test_df, mini_ddsm_test_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nCombined dataset sizes:\")\n",
    "print(f\"Train set: {len(combined_train_df)}\")\n",
    "print(f\"Validation set: {len(combined_val_df)}\")\n",
    "print(f\"Test set: {len(combined_test_df)}\")\n",
    "print(f'\\nCombined class distribution in train set:')\n",
    "print(combined_train_df['label'].value_counts())\n",
    "print(f'\\nCombined class distribution in validation set:')\n",
    "print(combined_val_df['label'].value_counts())\n",
    "print(f'\\nCombined class distribution in test set:')\n",
    "print(combined_test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dfc66d",
   "metadata": {},
   "source": [
    "### 1.2 Image loading and preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c2c854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660_312382431_png.rf.60f10fd25f27eba500354c40...</td>\n",
       "      <td>../raw_data/breast-cancer-detection/train/0/16...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37032_1243050806_png.rf.733846bab2dde1d3137703...</td>\n",
       "      <td>../raw_data/breast-cancer-detection/train/1/37...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2472_1387239105_png.rf.d2ad3d9ff1876a30491933e...</td>\n",
       "      <td>../raw_data/breast-cancer-detection/train/0/24...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>259_391410545_png.rf.f42b7e4e7c60e8113d12ff5c8...</td>\n",
       "      <td>../raw_data/breast-cancer-detection/train/0/25...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2066_1080373862_png.rf.a63e0a6f7806827934bda38...</td>\n",
       "      <td>../raw_data/breast-cancer-detection/train/0/20...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  \\\n",
       "0  1660_312382431_png.rf.60f10fd25f27eba500354c40...   \n",
       "1  37032_1243050806_png.rf.733846bab2dde1d3137703...   \n",
       "2  2472_1387239105_png.rf.d2ad3d9ff1876a30491933e...   \n",
       "3  259_391410545_png.rf.f42b7e4e7c60e8113d12ff5c8...   \n",
       "4  2066_1080373862_png.rf.a63e0a6f7806827934bda38...   \n",
       "\n",
       "                                          image_path  label  split  \n",
       "0  ../raw_data/breast-cancer-detection/train/0/16...      0  train  \n",
       "1  ../raw_data/breast-cancer-detection/train/1/37...      1  train  \n",
       "2  ../raw_data/breast-cancer-detection/train/0/24...      0  train  \n",
       "3  ../raw_data/breast-cancer-detection/train/0/25...      0  train  \n",
       "4  ../raw_data/breast-cancer-detection/train/0/20...      0  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded4d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_concurrently(df, preprocess_image_func, max_workers=4):\n",
    "    \"\"\"\n",
    "    Load images concurrently using ThreadPoolExecutor.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "        preprocess_image_func (function): Function to preprocess images.\n",
    "        max_workers (int): Number of threads to use.\n",
    "    Returns:\n",
    "        tuple: Numpy arrays of images and labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    def process_row(row):\n",
    "        img_path = row['image_path']\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            processed_image = preprocess_image_func(image)\n",
    "            return processed_image, row['label']\n",
    "        else:\n",
    "            print(f\"Warning: Image not found at {img_path}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_row, row) for _, row in df.iterrows()]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                img, label = result\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05f8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609e737",
   "metadata": {},
   "source": [
    "## 2. Model training and evaluation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c54fea",
   "metadata": {},
   "source": [
    "### 2.1 Model training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4715d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224, 3)):\n",
    "    # Base model with pre-trained weights\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    # Freeze first 75% of layers\n",
    "    # num_layers = len(base_model.layers)\n",
    "    # freeze_up_to = int(num_layers * 0.75)  # Calculate 75% cutoff\n",
    "    # for layer in base_model.layers[:freeze_up_to]:\n",
    "    #     layer.trainable = False  # Freeze individual layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Explicitly define inputs and pass training=False for batch norm\n",
    "    inputs = base_model.input\n",
    "    x = base_model(inputs, training=False)  # Critical for batch norm handling[1][4]\n",
    "\n",
    "    # Existing top layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=3e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \"precision\", \"recall\", 'AUC']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19  # Changed import\n",
    "\n",
    "def create_model_vgg19(input_shape=(224, 224, 3)):\n",
    "    # Base model with pre-trained weights\n",
    "    base_model = VGG19(  # Changed to VGG19\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build model\n",
    "    inputs = base_model.input\n",
    "    x = base_model(inputs)  # Removed training=False (not needed for VGG19)\n",
    "\n",
    "    # Adjusted top layers for VGG19\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)  # Increased from 128 to 256\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)  # Additional layer\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),  # Reduced learning rate\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', \"precision\", \"recall\", 'AUC']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7438e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 16:55:45.881962: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-06-18 16:55:45.882064: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-06-18 16:55:45.882108: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-06-18 16:55:45.882493: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-06-18 16:55:45.882638: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,188,737</span> (77.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,188,737\u001b[0m (77.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,353</span> (642.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,353\u001b[0m (642.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_test = create_model_vgg19()\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75dc5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mammography_classifier(train_df, val_df, test_df,\n",
    "                                 preprocess_image_func,\n",
    "                                 epochs=100,\n",
    "                                 use_callbacks=True,\n",
    "                                 use_data_augmentation=False):\n",
    "    \"\"\"\n",
    "    Complete binary classification training pipeline with patient-based splits\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): DataFrame for training set.\n",
    "        val_df (pd.DataFrame): DataFrame for validation set.\n",
    "        test_df (pd.DataFrame): DataFrame for test set.\n",
    "        preprocess_image_func (function): Function to preprocess images.\n",
    "    Returns:\n",
    "        tuple: Trained model, training history, and test data.\n",
    "    \"\"\"\n",
    "    # Load and preprocess data for each split\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    X_train, y_train = load_data_concurrently(train_df, preprocess_image_func)\n",
    "    X_val, y_val = load_data_concurrently(val_df, preprocess_image_func)\n",
    "    X_test, y_test = load_data_concurrently(test_df, preprocess_image_func)\n",
    "\n",
    "    print(f\"Training samples: {len(X_train)} with {sum(y_train == 0)} non-cancer images and {sum(y_train == 1)} cancer images.\")\n",
    "    print(f\"Validation samples: {len(X_val)} with {sum(y_val == 0)} non-cancer images and {sum(y_val == 1)} cancer images.\")\n",
    "    print(f\"Test samples: {len(X_test)} with {sum(y_test == 0)} non-cancer images and {sum(y_test == 1)} cancer images.\")\n",
    "\n",
    "    # Create and compile model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = create_model_vgg19(input_shape)\n",
    "\n",
    "    print(\"\\nModel Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Data augmentation\n",
    "    datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest'\n",
    "                                 )\n",
    "\n",
    "    # Callbacks\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_AUC',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode = 'max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    plateau = ReduceLROnPlateau(\n",
    "        monitor='val_AUC',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "        min_lr=0.000001\n",
    "    )\n",
    "\n",
    "    if use_callbacks:\n",
    "        callbacks = [es, plateau]\n",
    "    else:\n",
    "        callbacks = None\n",
    "\n",
    "    # Training with 4-fold validation strategy\n",
    "    print(\"Starting training...\")\n",
    "    if use_data_augmentation:\n",
    "        train_generator = datagen.flow(X_train, y_train, batch_size=64)\n",
    "        steps_per_epoch = len(X_train) // 64\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=64,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    return model, history, X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b81f21",
   "metadata": {},
   "source": [
    "### 2.2 Model evalution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d852dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test set\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        X_test (np.ndarray): Test images.\n",
    "        y_test (np.ndarray): Test labels.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nFinal Test Set Evaluation:\")\n",
    "    print(\"=\"*50)\n",
    "    target_names = ['Non-Cancer (Benign+Normal)', 'Cancer']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate medical metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall for cancer detection\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Recall for non-cancer detection\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Positive Predictive Value\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "\n",
    "    print(f\"\\nMedical Performance Metrics:\")\n",
    "    print(f\"Sensitivity (Cancer Detection Rate): {sensitivity:.3f}\")\n",
    "    print(f\"Specificity (Non-Cancer Detection Rate): {specificity:.3f}\")\n",
    "    print(f\"Positive Predictive Value (PPV): {ppv:.3f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {npv:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304ea404",
   "metadata": {},
   "source": [
    "## 3. Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a852167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40cd5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n",
      "Training samples: 5366 with 2683 non-cancer images and 2683 cancer images.\n",
      "Validation samples: 1819 with 1180 non-cancer images and 639 cancer images.\n",
      "Test samples: 1520 with 968 non-cancer images and 552 cancer images.\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,188,737</span> (77.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,188,737\u001b[0m (77.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,353</span> (642.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,353\u001b[0m (642.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 09:51:51.263307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - AUC: 0.4741 - accuracy: 0.4753 - loss: 0.9110 - precision: 0.4793 - recall: 0.4917 - val_AUC: 0.5200 - val_accuracy: 0.5646 - val_loss: 0.6883 - val_precision: 0.3554 - val_recall: 0.2942 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2s/step - AUC: 0.4904 - accuracy: 0.4788 - loss: 0.8620 - precision: 0.4899 - recall: 0.4838 - val_AUC: 0.5215 - val_accuracy: 0.5607 - val_loss: 0.6878 - val_precision: 0.3485 - val_recall: 0.2879 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - AUC: 0.4928 - accuracy: 0.4940 - loss: 0.8464 - precision: 0.4958 - recall: 0.4778 - val_AUC: 0.5185 - val_accuracy: 0.5250 - val_loss: 0.6959 - val_precision: 0.3560 - val_recall: 0.4351 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 3s/step - AUC: 0.5082 - accuracy: 0.4964 - loss: 0.8175 - precision: 0.5035 - recall: 0.4956 - val_AUC: 0.5176 - val_accuracy: 0.5536 - val_loss: 0.6904 - val_precision: 0.3536 - val_recall: 0.3271 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - AUC: 0.5017 - accuracy: 0.5098 - loss: 0.8250 - precision: 0.4985 - recall: 0.4883\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 4s/step - AUC: 0.5017 - accuracy: 0.5098 - loss: 0.8251 - precision: 0.4986 - recall: 0.4885 - val_AUC: 0.5186 - val_accuracy: 0.4437 - val_loss: 0.7066 - val_precision: 0.3592 - val_recall: 0.7449 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 5s/step - AUC: 0.4887 - accuracy: 0.4924 - loss: 0.8362 - precision: 0.4868 - recall: 0.5025 - val_AUC: 0.5193 - val_accuracy: 0.5250 - val_loss: 0.6964 - val_precision: 0.3606 - val_recall: 0.4554 - learning_rate: 5.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 5s/step - AUC: 0.4911 - accuracy: 0.4894 - loss: 0.8335 - precision: 0.4875 - recall: 0.4817 - val_AUC: 0.5195 - val_accuracy: 0.3859 - val_loss: 0.7161 - val_precision: 0.3582 - val_recall: 0.9452 - learning_rate: 5.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - AUC: 0.5113 - accuracy: 0.5163 - loss: 0.8161 - precision: 0.5147 - recall: 0.5418\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 5s/step - AUC: 0.5112 - accuracy: 0.5161 - loss: 0.8161 - precision: 0.5146 - recall: 0.5416 - val_AUC: 0.5183 - val_accuracy: 0.5580 - val_loss: 0.6887 - val_precision: 0.3497 - val_recall: 0.3005 - learning_rate: 5.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 4s/step - AUC: 0.4926 - accuracy: 0.4895 - loss: 0.8231 - precision: 0.4817 - recall: 0.4438 - val_AUC: 0.5197 - val_accuracy: 0.4915 - val_loss: 0.6999 - val_precision: 0.3535 - val_recall: 0.5399 - learning_rate: 2.5000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 4s/step - AUC: 0.5026 - accuracy: 0.5041 - loss: 0.8205 - precision: 0.5081 - recall: 0.5078 - val_AUC: 0.5190 - val_accuracy: 0.4970 - val_loss: 0.6993 - val_precision: 0.3547 - val_recall: 0.5274 - learning_rate: 2.5000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - AUC: 0.5096 - accuracy: 0.5145 - loss: 0.8127 - precision: 0.5264 - recall: 0.5096\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 4s/step - AUC: 0.5094 - accuracy: 0.5144 - loss: 0.8129 - precision: 0.5262 - recall: 0.5095 - val_AUC: 0.5193 - val_accuracy: 0.5146 - val_loss: 0.6972 - val_precision: 0.3565 - val_recall: 0.4742 - learning_rate: 2.5000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 3s/step - AUC: 0.5011 - accuracy: 0.5030 - loss: 0.8218 - precision: 0.4956 - recall: 0.4960 - val_AUC: 0.5201 - val_accuracy: 0.4678 - val_loss: 0.7040 - val_precision: 0.3651 - val_recall: 0.6964 - learning_rate: 1.2500e-05\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 963ms/step\n",
      "\n",
      "Final Test Set Evaluation:\n",
      "==================================================\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "Non-Cancer (Benign+Normal)       0.66      0.81      0.73       968\n",
      "                    Cancer       0.44      0.25      0.32       552\n",
      "\n",
      "                  accuracy                           0.61      1520\n",
      "                 macro avg       0.55      0.53      0.52      1520\n",
      "              weighted avg       0.58      0.61      0.58      1520\n",
      "\n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Medical Performance Metrics:\n",
      "Sensitivity (Cancer Detection Rate): 0.254\n",
      "Specificity (Non-Cancer Detection Rate): 0.814\n",
      "Positive Predictive Value (PPV): 0.438\n",
      "Negative Predictive Value (NPV): 0.657\n"
     ]
    }
   ],
   "source": [
    "model, history, X_train, y_train, X_val, y_val, X_test, y_test = train_mammography_classifier(\n",
    "    combined_train_df,\n",
    "    combined_val_df,\n",
    "    combined_test_df,\n",
    "    preprocess_image_func=preproc.preprocess_image,\n",
    "    epochs=50,\n",
    "    use_callbacks=True,\n",
    "    use_data_augmentation=False\n",
    ")\n",
    "\n",
    "evaluate_final_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d14d0",
   "metadata": {},
   "source": [
    "## Try #2 (with data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mammography_classifier_2(X_train, y_train, X_val, y_val,\n",
    "                                 epochs=100,\n",
    "                                 use_callbacks=True,\n",
    "                                 use_data_augmentation=False):\n",
    "    \"\"\"\n",
    "    Complete binary classification training pipeline with patient-based splits\n",
    "    Args:\n",
    "        X_train (np.ndarray): Training images.\n",
    "        y_train (np.ndarray): Training labels.\n",
    "        X_val (np.ndarray): Validation images.\n",
    "        y_val (np.ndarray): Validation labels.\n",
    "        epochs (int): Number of training epochs.\n",
    "        use_callbacks (bool): Whether to use callbacks during training.\n",
    "        use_data_augmentation (bool): Whether to apply data augmentation.\n",
    "    Returns:\n",
    "        tuple: Trained model, training history\n",
    "    \"\"\"\n",
    "\n",
    "    # Create and compile model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = create_model_vgg19(input_shape)\n",
    "\n",
    "    print(\"\\nModel Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Data augmentation\n",
    "    datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1,\n",
    "                                 horizontal_flip=True,\n",
    "                                 fill_mode='nearest'\n",
    "                                 )\n",
    "\n",
    "    # Callbacks\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_AUC',\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode = 'max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    plateau = ReduceLROnPlateau(\n",
    "        monitor='val_AUC',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode='max',\n",
    "        min_lr=0.000001\n",
    "    )\n",
    "\n",
    "    if use_callbacks:\n",
    "        callbacks = [es, plateau]\n",
    "    else:\n",
    "        callbacks = None\n",
    "\n",
    "    # Training with 4-fold validation strategy\n",
    "    print(\"Starting training...\")\n",
    "    if use_data_augmentation:\n",
    "        train_generator = datagen.flow(X_train, y_train, batch_size=64)\n",
    "        steps_per_epoch = len(X_train) // 64\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=64,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,188,737</span> (77.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,188,737\u001b[0m (77.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,353</span> (642.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,353\u001b[0m (642.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - AUC: 0.4975 - accuracy: 0.4908 - loss: 0.9455 - precision: 0.4930 - recall: 0.5352 - val_AUC: 0.4686 - val_accuracy: 0.3513 - val_loss: 0.7530 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 4s/step - AUC: 0.4987 - accuracy: 0.4954 - loss: 0.9060 - precision: 0.4952 - recall: 0.4920 - val_AUC: 0.4695 - val_accuracy: 0.3480 - val_loss: 0.7319 - val_precision: 0.3488 - val_recall: 0.9875 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 4s/step - AUC: 0.4894 - accuracy: 0.4911 - loss: 0.8945 - precision: 0.4927 - recall: 0.4965 - val_AUC: 0.4750 - val_accuracy: 0.3513 - val_loss: 0.7779 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 5s/step - AUC: 0.5099 - accuracy: 0.4989 - loss: 0.8671 - precision: 0.4942 - recall: 0.5238 - val_AUC: 0.4794 - val_accuracy: 0.3513 - val_loss: 0.7344 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 5s/step - AUC: 0.5258 - accuracy: 0.5113 - loss: 0.8284 - precision: 0.5009 - recall: 0.4937 - val_AUC: 0.4820 - val_accuracy: 0.3513 - val_loss: 0.7488 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 5s/step - AUC: 0.5019 - accuracy: 0.5001 - loss: 0.8517 - precision: 0.5068 - recall: 0.5348 - val_AUC: 0.4801 - val_accuracy: 0.4568 - val_loss: 0.7028 - val_precision: 0.3307 - val_recall: 0.5336 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 5s/step - AUC: 0.4911 - accuracy: 0.4960 - loss: 0.8612 - precision: 0.4864 - recall: 0.4622 - val_AUC: 0.4860 - val_accuracy: 0.3513 - val_loss: 0.7752 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 4s/step - AUC: 0.4904 - accuracy: 0.4883 - loss: 0.8646 - precision: 0.4772 - recall: 0.5111 - val_AUC: 0.4883 - val_accuracy: 0.3513 - val_loss: 0.8100 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 5s/step - AUC: 0.5131 - accuracy: 0.5057 - loss: 0.8425 - precision: 0.4959 - recall: 0.5190 - val_AUC: 0.4894 - val_accuracy: 0.3513 - val_loss: 0.7306 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 4s/step - AUC: 0.4978 - accuracy: 0.5031 - loss: 0.8489 - precision: 0.4947 - recall: 0.4909 - val_AUC: 0.4898 - val_accuracy: 0.3513 - val_loss: 0.7652 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 4s/step - AUC: 0.4913 - accuracy: 0.4911 - loss: 0.8436 - precision: 0.4942 - recall: 0.5059 - val_AUC: 0.4875 - val_accuracy: 0.3491 - val_loss: 0.7272 - val_precision: 0.3497 - val_recall: 0.9922 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 4s/step - AUC: 0.4994 - accuracy: 0.5009 - loss: 0.8543 - precision: 0.4928 - recall: 0.4927 - val_AUC: 0.4914 - val_accuracy: 0.3513 - val_loss: 0.7544 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 4s/step - AUC: 0.5006 - accuracy: 0.5011 - loss: 0.8370 - precision: 0.4913 - recall: 0.4971 - val_AUC: 0.4911 - val_accuracy: 0.3513 - val_loss: 0.7565 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3s/step - AUC: 0.5076 - accuracy: 0.5033 - loss: 0.8245 - precision: 0.5040 - recall: 0.5047 - val_AUC: 0.4928 - val_accuracy: 0.3513 - val_loss: 0.7416 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - AUC: 0.5000 - accuracy: 0.4952 - loss: 0.8209 - precision: 0.4908 - recall: 0.5042 - val_AUC: 0.4935 - val_accuracy: 0.3513 - val_loss: 0.7471 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1630s\u001b[0m 20s/step - AUC: 0.4964 - accuracy: 0.4949 - loss: 0.8346 - precision: 0.4920 - recall: 0.5020 - val_AUC: 0.4960 - val_accuracy: 0.4162 - val_loss: 0.7074 - val_precision: 0.3572 - val_recall: 0.8279 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - AUC: 0.4947 - accuracy: 0.4968 - loss: 0.8286 - precision: 0.4966 - recall: 0.4698 - val_AUC: 0.4966 - val_accuracy: 0.3513 - val_loss: 0.7472 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - AUC: 0.5056 - accuracy: 0.5018 - loss: 0.8179 - precision: 0.4968 - recall: 0.5127 - val_AUC: 0.4914 - val_accuracy: 0.3513 - val_loss: 0.7359 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2237s\u001b[0m 27s/step - AUC: 0.4895 - accuracy: 0.5015 - loss: 0.8295 - precision: 0.4913 - recall: 0.4798 - val_AUC: 0.4952 - val_accuracy: 0.3513 - val_loss: 0.7423 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - AUC: 0.4892 - accuracy: 0.4911 - loss: 0.8260 - precision: 0.4915 - recall: 0.5117\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - AUC: 0.4892 - accuracy: 0.4911 - loss: 0.8261 - precision: 0.4915 - recall: 0.5116 - val_AUC: 0.4955 - val_accuracy: 0.4349 - val_loss: 0.7035 - val_precision: 0.3565 - val_recall: 0.7559 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - AUC: 0.4957 - accuracy: 0.5006 - loss: 0.8152 - precision: 0.5003 - recall: 0.4684 - val_AUC: 0.4942 - val_accuracy: 0.3513 - val_loss: 0.7300 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m995s\u001b[0m 12s/step - AUC: 0.5084 - accuracy: 0.5043 - loss: 0.8034 - precision: 0.5003 - recall: 0.4915 - val_AUC: 0.4980 - val_accuracy: 0.3513 - val_loss: 0.7360 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - AUC: 0.4999 - accuracy: 0.5090 - loss: 0.8121 - precision: 0.5230 - recall: 0.5289 - val_AUC: 0.4946 - val_accuracy: 0.3650 - val_loss: 0.7126 - val_precision: 0.3519 - val_recall: 0.9593 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - AUC: 0.5017 - accuracy: 0.5036 - loss: 0.8094 - precision: 0.4990 - recall: 0.4746 - val_AUC: 0.4964 - val_accuracy: 0.3513 - val_loss: 0.7367 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - AUC: 0.5134 - accuracy: 0.5040 - loss: 0.8036 - precision: 0.5049 - recall: 0.5080\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - AUC: 0.5133 - accuracy: 0.5039 - loss: 0.8037 - precision: 0.5048 - recall: 0.5079 - val_AUC: 0.4965 - val_accuracy: 0.3513 - val_loss: 0.7466 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - AUC: 0.5034 - accuracy: 0.5032 - loss: 0.8092 - precision: 0.5100 - recall: 0.5245 - val_AUC: 0.4981 - val_accuracy: 0.3513 - val_loss: 0.7310 - val_precision: 0.3513 - val_recall: 1.0000 - learning_rate: 2.5000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m73/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m39s\u001b[0m 4s/step - AUC: 0.4981 - accuracy: 0.4962 - loss: 0.8106 - precision: 0.4920 - recall: 0.4970"
     ]
    }
   ],
   "source": [
    "model_2, history_2 = train_mammography_classifier_2(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    epochs=50,\n",
    "    use_callbacks=True,\n",
    "    use_data_augmentation=False\n",
    ")\n",
    "\n",
    "evaluate_final_model(model_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60f726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae947529",
   "metadata": {},
   "source": [
    "## 4. RSNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18367a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train_1 = np.load('../raw_data/RSNA_full/X_train_1.npy')\n",
    "# X_train_2 = np.load('../raw_data/RSNA_full/X_train_2.npy')\n",
    "# X_train_3 = np.load('../raw_data/RSNA_full/X_train_3.npy')\n",
    "# X_train_4 = np.load('../raw_data/RSNA_full/X_train_4.npy')\n",
    "X_val_1 = np.load('../raw_data/RSNA_full/X_val_1.npy')\n",
    "\n",
    "# X_train = np.concatenate([X_train_1, X_train_2, X_train_3], axis=0)\n",
    "X_val = X_val_1\n",
    "\n",
    "y_train_1 = np.load('../raw_data/RSNA_full/y_train_1.npy')\n",
    "# y_train_2 = np.load('../raw_data/RSNA_full/y_train_2.npy')\n",
    "# y_train_3 = np.load('../raw_data/RSNA_full/y_train_3.npy')\n",
    "# y_train_4 = np.load('../raw_data/RSNA_full/y_train_4.npy')\n",
    "y_val_1 = np.load('../raw_data/RSNA_full/y_val_1.npy')\n",
    "# y_train = np.concatenate([y_train_1, y_train_2, y_train_3], axis=0)\n",
    "y_val = y_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f198282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_3, history_3 = train_mammography_classifier_2(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    epochs=50,\n",
    "    use_callbacks=True,\n",
    "    use_data_augmentation=False\n",
    ")\n",
    "\n",
    "evaluate_final_model(model_3, X_train_4, y_train_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon-breast-cancer-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
