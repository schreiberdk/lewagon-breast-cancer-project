{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mattis' code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Tensorflow imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Custom imports\n",
    "from classification.ml_logic.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. 7808 records found.\n",
      "                             fullPath                fileName View   Side  \\\n",
      "0    Benign\\0029\\C_0029_1.LEFT_CC.jpg    C_0029_1.LEFT_CC.jpg   CC   LEFT   \n",
      "1   Benign\\0029\\C_0029_1.LEFT_MLO.jpg   C_0029_1.LEFT_MLO.jpg  MLO   LEFT   \n",
      "2   Benign\\0029\\C_0029_1.RIGHT_CC.jpg   C_0029_1.RIGHT_CC.jpg   CC  RIGHT   \n",
      "3  Benign\\0029\\C_0029_1.RIGHT_MLO.jpg  C_0029_1.RIGHT_MLO.jpg  MLO  RIGHT   \n",
      "4    Benign\\0033\\C_0033_1.LEFT_CC.jpg    C_0033_1.LEFT_CC.jpg   CC   LEFT   \n",
      "\n",
      "   Status                          Tumour_Contour Tumour_Contour2   Age  \\\n",
      "0  Benign   Benign\\0029\\C_0029_1.LEFT_CC_Mask.jpg               -  66.0   \n",
      "1  Benign  Benign\\0029\\C_0029_1.LEFT_MLO_Mask.jpg               -  66.0   \n",
      "2  Benign                                       -               -  66.0   \n",
      "3  Benign                                       -               -  66.0   \n",
      "4  Benign                                       -               -  60.0   \n",
      "\n",
      "   Density  \n",
      "0        3  \n",
      "1        3  \n",
      "2        3  \n",
      "3        3  \n",
      "4        3  \n",
      "Filtered images: 7808 records remaining after removing masks.\n",
      "                                fullPath                fileName View   Side  \\\n",
      "7803  Normal/4607/D_4607_1.RIGHT_MLO.jpg  D_4607_1.RIGHT_MLO.jpg  MLO  RIGHT   \n",
      "7804    Normal/4608/D_4608_1.LEFT_CC.jpg    D_4608_1.LEFT_CC.jpg   CC   LEFT   \n",
      "7805   Normal/4608/D_4608_1.LEFT_MLO.jpg   D_4608_1.LEFT_MLO.jpg  MLO   LEFT   \n",
      "7806   Normal/4608/D_4608_1.RIGHT_CC.jpg   D_4608_1.RIGHT_CC.jpg   CC  RIGHT   \n",
      "7807  Normal/4608/D_4608_1.RIGHT_MLO.jpg  D_4608_1.RIGHT_MLO.jpg  MLO  RIGHT   \n",
      "\n",
      "      Status Tumour_Contour Tumour_Contour2   Age  Density patient_id  \\\n",
      "7803  Normal              -               -  41.0        1       4607   \n",
      "7804  Normal              -               -  39.0        2       4608   \n",
      "7805  Normal              -               -  39.0        2       4608   \n",
      "7806  Normal              -               -  39.0        2       4608   \n",
      "7807  Normal              -               -  39.0        2       4608   \n",
      "\n",
      "      binary_label  \n",
      "7803             0  \n",
      "7804             0  \n",
      "7805             0  \n",
      "7806             0  \n",
      "7807             0  \n",
      "Final dataset size after removing missing labels: 7808 records.\n",
      "Total images: 7808\n",
      "Total unique patients: 1692\n",
      "Original class distribution:\n",
      "Status\n",
      "Cancer    2716\n",
      "Benign    2684\n",
      "Normal    2408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Binary class distribution:\n",
      "Non-Cancer (Benign + Normal): 5092\n",
      "Cancer: 2716\n"
     ]
    }
   ],
   "source": [
    "# Define file path\n",
    "MASTER_PATH = '../raw_data/MINI-DDSM-Complete-JPEG-8'\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(os.path.join(MASTER_PATH, 'DataWMask.xlsx'))\n",
    "print(f'Data loaded successfully. {len(df)} records found.')\n",
    "print(df.head())\n",
    "\n",
    "# Replace backslashes with forward slashes in fullPath\n",
    "df['fullPath'] = df['fullPath'].str.replace('\\\\', '/', regex=False)\n",
    "# Ensure fullPath is a string\n",
    "df['fullPath'] = df['fullPath'].astype(str)\n",
    "\n",
    "# Filter out mask files (keep only original images)\n",
    "df_images = df[~df['fileName'].str.contains('Mask', na=False)]\n",
    "print(f'Filtered images: {len(df_images)} records remaining after removing masks.')\n",
    "\n",
    "# Extract patiend ID from fileName (format: C_{patient_id}_1_LATERALITY_VIEW.jpg)\n",
    "df_images['fileName'] = df_images['fileName'].astype(str).str.strip()\n",
    "df_images['patient_id'] = df_images['fileName'].str.extract(r'\\w_(\\d+)_1')\n",
    "\n",
    "# Create full image paths\n",
    "#df_images['full_image_path'] = df_images['fullPath']\n",
    "\n",
    "# Binary mapping: Cancer = 1, Benign and Normal = 0\n",
    "def create_binary_labels(status):\n",
    "    if status == 'Cancer':\n",
    "        return 1\n",
    "    else: # Benign or Normal\n",
    "        return 0\n",
    "\n",
    "df_images['binary_label'] = df_images['Status'].apply(create_binary_labels)\n",
    "print(df_images.tail())\n",
    "\n",
    "# Remove any rows with missing labels\n",
    "df_images = df_images.dropna(subset=['binary_label', 'patient_id'])\n",
    "print(f'Final dataset size after removing missing labels: {len(df_images)} records.')\n",
    "\n",
    "print(f\"Total images: {len(df_images)}\")\n",
    "print(f\"Total unique patients: {df_images['patient_id'].nunique()}\")\n",
    "print(f\"Original class distribution:\\n{df_images['Status'].value_counts()}\")\n",
    "print(f\"\\nBinary class distribution:\")\n",
    "print(f\"Non-Cancer (Benign + Normal): {len(df_images[df_images['binary_label'] == 0])}\")\n",
    "print(f\"Cancer: {len(df_images[df_images['binary_label'] == 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Patient-based Train/Val/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient distribution:\n",
      "Train patients: 1184\n",
      "Validation patients: 253\n",
      "Test patients: 255\n",
      "\n",
      "Image distribution:\n",
      "Train images: 5480 (Cancer: 1880, Non-Cancer: 3600)\n",
      "Val images: 1144 (Cancer: 412, Non-Cancer: 732)\n",
      "Test images: 1184 (Cancer: 424, Non-Cancer: 760)\n",
      "✓ No patient leakage detected!\n"
     ]
    }
   ],
   "source": [
    "def patient_based_split(df_images, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data by patient ID to avoid data leakage.\n",
    "    Args:\n",
    "        df_images (pd.DataFrame): DataFrame containing image data with 'patient_id' and 'Status'.\n",
    "        train_ratio (float): Proportion of data to use for training.\n",
    "        val_ratio (float): Proportion of data to use for validation.\n",
    "        test_ratio (float): Proportion of data to use for testing.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "    Returns:\n",
    "        tuple: DataFrames for train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    # Get unique patients with their status\n",
    "    patient_info = df_images.groupby('patient_id')['Status'].first().reset_index()\n",
    "    patient_info['binary_label'] = patient_info['Status'].apply(create_binary_labels)\n",
    "\n",
    "    unique_patients = patient_info['patient_id'].unique()\n",
    "\n",
    "    # Shuffle patients\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(unique_patients)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_patients = len(unique_patients)\n",
    "    train_size = int(train_ratio * total_patients)\n",
    "    val_size = int(val_ratio * total_patients)\n",
    "\n",
    "    # Split patient IDs\n",
    "    train_patients = unique_patients[:train_size]\n",
    "    val_patients = unique_patients[train_size:train_size+val_size]\n",
    "    test_patients = unique_patients[train_size+val_size:]\n",
    "\n",
    "    print(f\"\\nPatient distribution:\")\n",
    "    print(f\"Train patients: {len(train_patients)}\")\n",
    "    print(f\"Validation patients: {len(val_patients)}\")\n",
    "    print(f\"Test patients: {len(test_patients)}\")\n",
    "\n",
    "    # Assign split labels to all images based on patient ID\n",
    "    def assign_split(patient_id):\n",
    "        if patient_id in train_patients:\n",
    "            return 'train'\n",
    "        elif patient_id in val_patients:\n",
    "            return 'val'\n",
    "        else:\n",
    "            return 'test'\n",
    "\n",
    "    df_images['split'] = df_images['patient_id'].apply(assign_split)\n",
    "\n",
    "    # Create separate dataframes\n",
    "    train_df = df_images[df_images['split'] == 'train'].copy()\n",
    "    val_df = df_images[df_images['split'] == 'val'].copy()\n",
    "    test_df = df_images[df_images['split'] == 'test'].copy()\n",
    "\n",
    "    # Print detailed statistics\n",
    "    print(f\"\\nImage distribution:\")\n",
    "    print(f\"Train images: {len(train_df)} (Cancer: {sum(train_df['binary_label'])}, Non-Cancer: {len(train_df) - sum(train_df['binary_label'])})\")\n",
    "    print(f\"Val images: {len(val_df)} (Cancer: {sum(val_df['binary_label'])}, Non-Cancer: {len(val_df) - sum(val_df['binary_label'])})\")\n",
    "    print(f\"Test images: {len(test_df)} (Cancer: {sum(test_df['binary_label'])}, Non-Cancer: {len(test_df) - sum(test_df['binary_label'])})\")\n",
    "\n",
    "    # Verify no patient leakage\n",
    "    train_patients_set = set(train_df['patient_id'].unique())\n",
    "    val_patients_set = set(val_df['patient_id'].unique())\n",
    "    test_patients_set = set(test_df['patient_id'].unique())\n",
    "\n",
    "    assert len(train_patients_set.intersection(val_patients_set)) == 0, \"Patient leakage between train and val!\"\n",
    "    assert len(train_patients_set.intersection(test_patients_set)) == 0, \"Patient leakage between train and test!\"\n",
    "    assert len(val_patients_set.intersection(test_patients_set)) == 0, \"Patient leakage between val and test!\"\n",
    "\n",
    "    print(\"✓ No patient leakage detected!\")\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Execute the split\n",
    "train_df, val_df, test_df = patient_based_split(df_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(df, preprocess_image_func):\n",
    "    \"\"\"\n",
    "    Load images and apply preprocessing for a specific split\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing image paths and labels.\n",
    "        preprocess_image_func (function): Function to preprocess images.\n",
    "    Returns:\n",
    "        tuple: Numpy arrays of images, labels, and patient IDs.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    patient_ids = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Load image\n",
    "            img_path = os.path.join(MASTER_PATH, row['fullPath'])\n",
    "            if os.path.exists(img_path):\n",
    "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Apply preprocessing\n",
    "                processed_image = preprocess_image_func(image)\n",
    "\n",
    "                images.append(processed_image)\n",
    "                labels.append(row['binary_label'])\n",
    "                patient_ids.append(row['patient_id'])\n",
    "            else:\n",
    "                print(f\"Warning: Image not found at {img_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['fileName']}: {str(e)}\")\n",
    "\n",
    "    return np.array(images), np.array(labels), patient_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_model(input_shape):\n",
    "    \"\"\"\n",
    "    Create CNN model for binary classification (Cancer vs Non-Cancer)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(3, 3))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(3, 3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(3, 3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Single output for binary classification\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mammography_classifier(train_df, val_df, test_df, preprocess_image_func):\n",
    "    \"\"\"\n",
    "    Complete binary classification training pipeline with patient-based splits\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): DataFrame for training set.\n",
    "        val_df (pd.DataFrame): DataFrame for validation set.\n",
    "        test_df (pd.DataFrame): DataFrame for test set.\n",
    "        preprocess_image_func (function): Function to preprocess images.\n",
    "    Returns:\n",
    "        tuple: Trained model, training history, and test data.\n",
    "    \"\"\"\n",
    "    # Load and preprocess data for each split\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    X_train, y_train, train_patient_ids = load_and_preprocess_data(train_df, preprocess_image_func)\n",
    "    X_val, y_val, val_patient_ids = load_and_preprocess_data(val_df, preprocess_image_func)\n",
    "    X_test, y_test, test_patient_ids = load_and_preprocess_data(test_df, preprocess_image_func)\n",
    "\n",
    "    print(f\"Training samples: {len(X_train)} from {len(set(train_patient_ids))} patients\")\n",
    "    print(f\"Validation samples: {len(X_val)} from {len(set(val_patient_ids))} patients\")\n",
    "    print(f\"Test samples: {len(X_test)} from {len(set(test_patient_ids))} patients\")\n",
    "\n",
    "    # Create model\n",
    "    input_shape = X_train.shape[1:]\n",
    "    model = create_binary_model(input_shape)\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy', 'recall', 'precision']\n",
    "    )\n",
    "\n",
    "    print(\"\\nModel Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # Data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    plateau = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=0.00001\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    history = model.fit(\n",
    "        # datagen.flow(X_train, y_train, batch_size=64),\n",
    "        X_train, y_train, batch_size=64,\n",
    "        epochs=30,\n",
    "        # steps_per_epoch=len(X_train) // 32,\n",
    "        callbacks=[es, plateau],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model, history, X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test set\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        X_test (np.ndarray): Test images.\n",
    "        y_test (np.ndarray): Test labels.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nFinal Test Set Evaluation:\")\n",
    "    print(\"=\"*50)\n",
    "    target_names = ['Non-Cancer (Benign+Normal)', 'Cancer']\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(\"[[True Non-Cancer, False Cancer]\")\n",
    "    print(\" [False Non-Cancer, True Cancer]]\")\n",
    "\n",
    "    # Calculate medical metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0  # Recall for cancer detection\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Recall for non-cancer detection\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Positive Predictive Value\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "\n",
    "    print(f\"\\nMedical Performance Metrics:\")\n",
    "    print(f\"Sensitivity (Cancer Detection Rate): {sensitivity:.3f}\")\n",
    "    print(f\"Specificity (Non-Cancer Detection Rate): {specificity:.3f}\")\n",
    "    print(f\"Positive Predictive Value (PPV): {ppv:.3f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {npv:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Execute pipeline and evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-metal in /Users/mattisweber/.pyenv/versions/3.10.6/envs/lewagon-breast-cancer-project/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/mattisweber/.pyenv/versions/3.10.6/envs/lewagon-breast-cancer-project/lib/python3.10/site-packages (from tensorflow-metal) (0.45.1)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/mattisweber/.pyenv/versions/3.10.6/envs/lewagon-breast-cancer-project/lib/python3.10/site-packages (from tensorflow-metal) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.6 (main, Jun  2 2025, 11:35:41) [Clang 17.0.0 (clang-1700.0.13.5)]\n",
      "TensorFlow version: 2.16.2\n",
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "tensorflow-metal is NOT installed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Physical devices:\", tf.config.list_physical_devices())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Check if tensorflow-metal is installed\n",
    "try:\n",
    "    import tensorflow_metal\n",
    "    print(\"tensorflow-metal is installed\")\n",
    "except ImportError:\n",
    "    print(\"tensorflow-metal is NOT installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:O'):\n",
    "    # Execute the pipeline\n",
    "    model, history, X_train, y_train, X_val, y_val, X_test, y_test = train_mammography_classifier(train_df, val_df, test_df, Preprocessor.preprocess_image)\n",
    "\n",
    "    # Evaluate the final model\n",
    "    evaluate_final_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 981292,
     "sourceId": 2052874,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 374361,
     "modelInstanceId": 353079,
     "sourceId": 433086,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "lewagon-breast-cancer-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
